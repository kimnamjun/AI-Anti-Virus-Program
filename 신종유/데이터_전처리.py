# -*- coding: utf-8 -*-
"""데이터 전처리.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DgJ1WZ1XmFPoTR46c96zZCv7VPOWDT4L

# word2vec
"""

from google.colab import drive
drive.mount('/content/drive')

import re
import json
import numpy as np
import pandas as pd

"""## 데이터 전처리

### Train 데이터 전처리
"""

table = {'sha256': list(), 'label': list(), 'imports': list()}
functions = dict()
functions_length = 0
pattern = re.compile(r'\W*(\w+)')

for n in range(6):
    num = 0
    with open(f'/content/drive/MyDrive/dataset/train_features_{n}.jsonl') as file:
        # jsonl 파일에서 json 파일 읽기
        while True:
            line = file.readline()
            if not line:
                break
            line_json = json.loads(line)

            # sha256, label 컬럼 추가
            if line_json['label'] == -1:
              continue
            table['sha256'].append(line_json['sha256'])    
            table['label'].append(line_json['label'])
            
            # imports 내 dll과 함수명 라벨 인코딩 후 추가
            imports = list()
            for key, value in line_json['imports'].items():
                for val in value:
                    res = re.match(pattern, val)
                    if res is None:
                        continue
                    val = res.group(1)
                    if val not in functions:
                        functions_length += 1
                        functions[val] = 'x' + str(functions_length)
                    # imports.append(functions[val])  # 함수 이름을 x123 으로 저장합니다.
                    imports.append(val)  # 함수 이름을 그대로 저장합니다.
            
            table['imports'].append(imports)

            num += 1
            if num % 1000 == 0:
                print(f'\rjsonl{n} : {num}', end='')
        print(f'\rjsonl{n} : {num}')

train_df = pd.DataFrame(table)

train_df

"""### Test 데이터 전처리"""

table = {'sha256': list(), 'label': list(), 'imports': list()}

num = 0
with open(f'/content/drive/MyDrive/dataset/test_features.jsonl') as file:
    while True:
        line = file.readline()
        if not line:
            break
        line_json = json.loads(line)

        if line_json['label'] == -1:
          continue
        table['sha256'].append(line_json['sha256'])    
        table['label'].append(line_json['label'])
        
        imports = list()
        for key, value in line_json['imports'].items():
            for val in value:
                res = re.match(pattern, val)
                if res is None:
                    continue
                val = res.group(1)
                if val in functions:
                    # imports.append(functions[val])
                    imports.append(val)
                else:
                    imports.append('x')
        
        table['imports'].append(imports)

        num += 1
        if num % 1000 == 0:
            print(f'\rjsonl_test : {num}', end='')
    print(f'\rjsonl_test : {num}')

test_df = pd.DataFrame(table)

test_df

"""### Functions DataFrame 생성"""

# 중복을 피해 추출한 함수 이름의 개수 확인
functions_df = pd.DataFrame([functions.keys(), functions.values()]).T
functions_df.columns = ['function', 'x']
functions_df

"""### 데이터 저장"""

# DataFrame 저장
# train_df.to_csv('/content/drive/MyDrive/dataset/JY_Dataset/train_main_features_JY.csv', index=False)
# test_df.to_csv('/content/drive/MyDrive/dataset/JY_Dataset/test_main_features_JY.csv', index=False)
# functions_df.to_csv('/content/drive/MyDrive/dataset/JY_Dataset/functions_JY.csv', index=False)

"""### **데이터 불러오기**"""

path = '/content/drive/MyDrive/dataset/JY_Dataset'
train_df = pd.read_csv(path + '/train_main_features_JY.csv')
test_df = pd.read_csv(path + '/test_main_features_JY.csv')
functions_df = pd.read_csv(path + '/functions_JY.csv')

"""## 하나의 해시가 가진 API의 최대 길이"""

# train test 데이터 분리
x_train, y_train = train_df['imports'], train_df['label']
x_test, y_test = test_df['imports'], test_df['label']

# 가장 많은 함수를 사용한 파일의 함수 사용의 개수 확인
max_length = 0
for functions in x_train:
    max_length = max(max_length, len(functions))
max_length

"""### **벡터 크기(상위 95%까지) 구하기**"""

a = train_df
a

a['length'] = a['imports'].map(lambda x: len(eval(x)))
a.head(20)

index = a[a['length'] > 279].index
train_279 = a.drop(index)
train_279.head(20)

b = test_df
b

b['length'] = b['imports'].map(lambda x: len(eval(x)))
b.head(20)

index = b[b['length'] > 279].index
test_279 = b.drop(index)
test_279.head(20)

# DataFrame 저장
train_279.to_csv('/content/drive/MyDrive/dataset/JY_Dataset/train_main_features+length_JY.csv', index=False)
test_279.to_csv('/content/drive/MyDrive/dataset/JY_Dataset/test_main_features+length_JY.csv', index=False)

import seaborn as sns

sns.boxplot(data=a, y="length")

a["length"].quantile(0.25)

a["length"].quantile(0.75)

IQR = a["length"].quantile(0.75) - a["length"].quantile(0.25)

a["length"].quantile(0.25) - (1.5*IQR)

a["length"].quantile(0.75) + (1.5*IQR)